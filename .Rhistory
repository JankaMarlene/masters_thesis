count(cog_df_cl,cluster)
# Cross-checking clustering results using table function
table(cog_df_cl$cluster,cog_label)
# Add the cluster information from cog_df_cl to clean_data
clean_data$cluster <- cog_df_cl$cluster
# Check the updated structure of clean_data
str(clean_data)
# Checking sex in cluster
table(cog_df_cl$cluster,clean_data$sex)
cluster_info <- clean_data %>%
select(participant_id, cluster)
# Load the participants.tsv file
participants <- read.delim("C:/Users/jankj/OneDrive/Desktop/masters_thesis/data/participants.tsv", na.strings = "n/a", header = TRUE)
# Check the structure of participants to identify a common identifier
str(participants)
# Merge the clean_data with participants based on a common identifier
merged_data <- participants %>%
left_join(cluster_info, by = "participant_id")
merged_data <- merged_data %>%
rename(cluster_2 = cluster)
merged_data <- merged_data %>%
mutate(cluster_2 = recode(cluster_2, '1' = 'badperformer', '2' = 'goodperformer'))
# Check the structure of the merged data to ensure everything is correct
str(merged_data)
# Optionally, save the merged data to a new file
write_tsv(merged_data, "C:/Users/jankj/OneDrive/Desktop/masters_thesis/data/merged_data.tsv")
View(merged_data)
load("clean_data.RData")
# Extract relevant columns from clean_data
cog_df <- clean_data[, c("group","z_pvt_reaction_time_w","z_tmt_a_time_w","z_tmt_b_time_w")]
# Check structure and summarize contents of cog_df
str(cog_df)
summary(cog_df)
# Store group labels in a separate variable and exclude label (group column) from the dataset to do clustering
# Later true labels will be used to check how good clustering turned out
cog_label <- cog_df$group
cog_df$group <- NULL
str(cog_df)
# Build distance matrix
# Since all values are continuous numerical values I use euclidean distance method
dist_mat <- dist(cog_df, method = 'euclidean')
# Now decide which linkage method to use
# Try different kinds of linkage methods after decide which performed better
# Build dendrogram by plotting hierarchical cluster object with hclust
# Specify linkage method via 'method' argument
hclust_ward <- hclust(dist_mat, method = 'ward')
plot(hclust_ward)
# Create the desired number of clusters
# Since I want two groups 'withPCS' and 'withoutPCS' number of clusters = 2
cut_ward <- cutree(hclust_ward, k = 4)
# To visualize clusters on dendrogram use abline function to draw the cut line
plot(hclust_ward)
rect.hclust(hclust_ward, k = 4, border = 2:30)
abline(h = 10, col = 'red')
# Visualize tree with different colored branches
ward_dend_obj <- as.dendrogram(hclust_ward)
ward_col_dend <- color_branches(ward_dend_obj, h = 10)
plot(ward_col_dend)
# Append cluster results obtained back in the original dataframe
# Use mutate
# Count how many observations were assigned to each cluster with the count function
cog_df_cl <- mutate(cog_df, cluster = cut_ward)
count(cog_df_cl,cluster)
# Cross-checking clustering results using table function
table(cog_df_cl$cluster,cog_label)
# Add the cluster information from cog_df_cl to clean_data
clean_data$cluster <- cog_df_cl$cluster
# Check the updated structure of clean_data
str(clean_data)
# Checking sex in cluster
table(cog_df_cl$cluster,clean_data$sex)
#--------
cluster_info <- clean_data %>%
select(participant_id, cluster)
# Load the participants.tsv file
participants <- read.delim("C:/Users/jankj/OneDrive/Desktop/masters_thesis/data/merged_data.tsv", na.strings = "n/a", header = TRUE)
# Check the structure of participants to identify a common identifier
str(participants)
# Merge the clean_data with participants based on a common identifier
merged_data <- participants %>%
left_join(cluster_info, by = "participant_id")
merged_data <- merged_data %>%
rename(cluster_4 = cluster)
# Check the structure of the merged data to ensure everything is correct
str(merged_data)
# Optionally, save the merged data to a new file
write_tsv(merged_data, "C:/Users/jankj/OneDrive/Desktop/masters_thesis/data/merged_data_all.tsv")
clear
clc
library(tidyverse)
library(dplyr)
# Import data
alldata <- read.delim("C:/Users/jankj/OneDrive/Desktop/masters_thesis/data/participants.tsv", na.strings = "n/a", header = TRUE)
# Subset of alldata that contains only the important variables
subset <- alldata %>%
select(participant_id,nr, age, sex, group, graduation, years_of_education, neurological_diseases_1, facit_f_FS, hads_a_total_score, hads_d_total_score, psqi_total_score, moca, pvt_reaction_time, nback_miss_1, nback_false_alarm_1 ,nback_miss_2 ,nback_false_alarm_2 ,tmt_a_time,tmt_b_time) %>%
mutate(tmt_diff = tmt_b_time - tmt_a_time)
# Convert 'moca' variable to a binary variable based on a cutoff score of 25
# 1 represents scores less than 26 (may) indicating cognitive impairment
# 0 represents scores more than 25 (may) indicating no cognitive impairment
subset <- subset %>%
mutate(moca = ifelse(moca > 25, 0, 1))
# Subset with all relevant cognitive data
cog_subset <- subset %>%
select(participant_id,nr, age, group, pvt_reaction_time, nback_miss_1, nback_false_alarm_1, nback_miss_2, nback_false_alarm_2, tmt_a_time, tmt_b_time)
# Summarize cog_subset
cog_subset %>%
summary()
# Summarize cog_subset
subset %>%
summary()
sex(F)
subset(sex)
sex
# Subset of alldata that contains only the important variables
subset <- alldata %>%
select(participant_id,nr, age, sex, group, graduation, years_of_education, neurological_diseases_1, facit_f_FS, hads_a_total_score, hads_d_total_score, psqi_total_score, moca, pvt_reaction_time, nback_miss_1, nback_false_alarm_1 ,nback_miss_2 ,nback_false_alarm_2 ,tmt_a_time,tmt_b_time) %>%
mutate(tmt_diff = tmt_b_time - tmt_a_time)
View(subset)
age
# Summarize cog_subset
cog_subset %>%
summary(sex=F)
summary(sex)
View(subset)
library(tidyverse)
library(dplyr)
# Import data
alldata <- read.delim("C:/Users/jankj/OneDrive/Desktop/masters_thesis/data/participants.tsv", na.strings = "n/a", header = TRUE)
# Subset of alldata that contains only the important variables
subset <- alldata %>%
select(participant_id,nr, age, sex, group, graduation, years_of_education, neurological_diseases_1, facit_f_FS, hads_a_total_score, hads_d_total_score, psqi_total_score, moca, pvt_reaction_time, nback_miss_1, nback_false_alarm_1 ,nback_miss_2 ,nback_false_alarm_2 ,tmt_a_time,tmt_b_time) %>%
mutate(tmt_diff = tmt_b_time - tmt_a_time)
# Convert 'moca' variable to a binary variable based on a cutoff score of 25
# 1 represents scores less than 26 (may) indicating cognitive impairment
# 0 represents scores more than 25 (may) indicating no cognitive impairment
subset <- subset %>%
mutate(moca = ifelse(moca > 25, 0, 1))
# Subset with all relevant cognitive data
cog_subset <- subset %>%
select(participant_id,nr, age, group, pvt_reaction_time, nback_miss_1, nback_false_alarm_1, nback_miss_2, nback_false_alarm_2, tmt_a_time, tmt_b_time)
# Summarize cog_subset
cog_subset %>%
summary()
# Summarize cog_subset
subset %>%
summary()
# Filter to get all "withPCS" rows
# Summary of "withPCS" group
cog_subset %>%
filter(group == "withPCS") %>%
summary(group == "withPCS")
# Filter to get all "withPCS" rows
# Summary of "withPCS" group
subset %>%
filter(group == "withPCS") %>%
summary(group == "withPCS")
# Filter to get all "withoutPCS" rows
# Summary of "withoutPCS" group
subset %>%
filter(group == "withoutPCS") %>%
summary(group == "withoutPCS")
View(subset)
# Checking for missing values
any(is.na(subset))
# Missing values = TRUE
# Removing rows with missing values
# cog_subset_clean <- cog_subset[complete.cases(cog_subset), ]
subset<- subset %>%
drop_na(pvt_reaction_time, nback_miss_1, nback_miss_2, tmt_a_time, tmt_b_time)
# Summarize cleaned dataframe
subset %>%
summary()
# Variables for which outliers are to be identified and winsorized
variables <- c("pvt_reaction_time","nback_miss_1","nback_miss_2","tmt_a_time","tmt_b_time")
# Initialize clean_data as a copy of subset
clean_data <- subset
# Function to winsorize a variable
winsorize_variable <- function(x) {
q1 <- quantile(x, 0.25)
q3 <- quantile(x, 0.75)
iqr <- IQR(x)
# Winsorization
x <- ifelse(x > q3 + 1.5 * iqr, q3 + 1.5 * iqr, x)
x <- ifelse(x < q1 - 1.5 * iqr, q1 - 1.5 * iqr, x)
x
}
# Loop over all variables
for (variable in variables) {
# Detect outliers
box_plot <- boxplot(subset[[variable]])$out
mtext(paste("Outliers for", variable, ":", paste(box_plot, collapse = ",")))
# Identify rows containing outliers
out_ind <- which(subset[[variable]] %in% c(box_plot))
cat("Indices of outliers for", variable, ":", out_ind, "\n")
cat("Rows with outliers for", variable, ":\n")
print(subset[out_ind,])
# Winsorize the variable and create a new column
winsorized_variable <- paste(variable, "w", sep = "_")
clean_data[[winsorized_variable]] <- winsorize_variable(subset[[variable]])
}
# Check the clean dataset
print(clean_data)
# Calculate tmt_diff_w
clean_data <- clean_data %>%
mutate(tmt_diff_w = tmt_b_time_w - tmt_a_time_w)
# Print clean_data to verify
print(clean_data)
# Test correlation
clean_data |>
select(pvt_reaction_time, nback_miss_1, nback_false_alarm_1, nback_miss_2, nback_false_alarm_2, tmt_a_time, tmt_b_time, tmt_diff) |>
cor(use = "pairwise.complete.obs") |>
round(2)
# Scatter plot of tmt_a_time vs. tmt_b_time faceted by age
ggplot(clean_data, aes(x = tmt_a_time, y = tmt_b_time, color = age)) +
geom_point()
# Scatter plot of nback_miss_1 vs. nback_miss_2 faceted by age
ggplot(clean_data, aes(x = nback_miss_1, y = nback_miss_2, color = age)) +
geom_point()
# Create age groups
clean_data <- clean_data %>%
mutate(
age_group = sapply(age, create_age_groups),
age_group_tmt_diff = sapply(age, create_age_groups_tmt_diff)
)
library(tidyverse)
library(dplyr)
# Import data
alldata <- read.delim("C:/Users/jankj/OneDrive/Desktop/masters_thesis/data/participants.tsv", na.strings = "n/a", header = TRUE)
# Subset of alldata that contains only the important variables
subset <- alldata %>%
select(participant_id,nr, age, sex, group, graduation, years_of_education, neurological_diseases_1, facit_f_FS, hads_a_total_score, hads_d_total_score, psqi_total_score, moca, pvt_reaction_time, nback_miss_1, nback_false_alarm_1 ,nback_miss_2 ,nback_false_alarm_2 ,tmt_a_time,tmt_b_time) %>%
mutate(tmt_diff = tmt_b_time - tmt_a_time)
# Convert 'moca' variable to a binary variable based on a cutoff score of 25
# 1 represents scores less than 26 (may) indicating cognitive impairment
# 0 represents scores more than 25 (may) indicating no cognitive impairment
subset <- subset %>%
mutate(moca = ifelse(moca > 25, 0, 1))
# Subset with all relevant cognitive data
cog_subset <- subset %>%
select(participant_id,nr, age, group, pvt_reaction_time, nback_miss_1, nback_false_alarm_1, nback_miss_2, nback_false_alarm_2, tmt_a_time, tmt_b_time)
# Summarize cog_subset
cog_subset %>%
summary()
# Filter to get all "withPCS" rows
# Summary of "withPCS" group
cog_subset %>%
filter(group == "withPCS") %>%
summary(group == "withPCS")
# Filter to get all "withoutPCS" rows
# Summary of "withoutPCS" group
cog_subset %>%
filter(group == "withoutPCS") %>%
summary(group == "withoutPCS")
# Checking for missing values
any(is.na(subset))
# Missing values = TRUE
# Removing rows with missing values
# cog_subset_clean <- cog_subset[complete.cases(cog_subset), ]
subset<- subset %>%
drop_na(pvt_reaction_time, nback_miss_1, nback_miss_2, tmt_a_time, tmt_b_time)
# Summarize cleaned dataframe
subset %>%
summary()
# Variables for which outliers are to be identified and winsorized
variables <- c("pvt_reaction_time","nback_miss_1","nback_miss_2","tmt_a_time","tmt_b_time")
# Initialize clean_data as a copy of subset
clean_data <- subset
# Function to winsorize a variable
winsorize_variable <- function(x) {
q1 <- quantile(x, 0.25)
q3 <- quantile(x, 0.75)
iqr <- IQR(x)
# Winsorization
x <- ifelse(x > q3 + 1.5 * iqr, q3 + 1.5 * iqr, x)
x <- ifelse(x < q1 - 1.5 * iqr, q1 - 1.5 * iqr, x)
x
}
# Loop over all variables
for (variable in variables) {
# Detect outliers
box_plot <- boxplot(subset[[variable]])$out
mtext(paste("Outliers for", variable, ":", paste(box_plot, collapse = ",")))
# Identify rows containing outliers
out_ind <- which(subset[[variable]] %in% c(box_plot))
cat("Indices of outliers for", variable, ":", out_ind, "\n")
cat("Rows with outliers for", variable, ":\n")
print(subset[out_ind,])
# Winsorize the variable and create a new column
winsorized_variable <- paste(variable, "w", sep = "_")
clean_data[[winsorized_variable]] <- winsorize_variable(subset[[variable]])
}
# Check the clean dataset
print(clean_data)
# Calculate tmt_diff_w
clean_data <- clean_data %>%
mutate(tmt_diff_w = tmt_b_time_w - tmt_a_time_w)
# Print clean_data to verify
print(clean_data)
# Test correlation
clean_data |>
select(pvt_reaction_time, nback_miss_1, nback_false_alarm_1, nback_miss_2, nback_false_alarm_2, tmt_a_time, tmt_b_time, tmt_diff) |>
cor(use = "pairwise.complete.obs") |>
round(2)
# Scatter plot of tmt_a_time vs. tmt_b_time faceted by age
ggplot(clean_data, aes(x = tmt_a_time, y = tmt_b_time, color = age)) +
geom_point()
# Scatter plot of nback_miss_1 vs. nback_miss_2 faceted by age
ggplot(clean_data, aes(x = nback_miss_1, y = nback_miss_2, color = age)) +
geom_point()
# Function to create age groups
create_age_groups <- function(age) {
if (age >= 18 & age <= 34) {
return("18-34 Years")
} else if (age >= 35 & age <= 49) {
return("35-49 Years")
} else if (age >= 50 & age <= 64) {
return("50-64 Years")
} else if (age >= 65 & age <= 80) {
return("65-80 Years")
}
}
# Function to create age groups for tmt_diff
create_age_groups_tmt_diff <- function(age) {
if (age >= 18 & age <= 24) {
return("18-24 Years")
} else if (age >= 25 & age <= 54) {
return("25-54 Years")
} else if (age >= 55 & age <= 64) {
return("55-64 Years")
} else if (age >= 65 & age <= 80) {
return("65-80 Years")
}
}
# Create age groups
clean_data <- clean_data %>%
mutate(
age_group = sapply(age, create_age_groups),
age_group_tmt_diff = sapply(age, create_age_groups_tmt_diff)
)
# Calculate mean and standard deviation for each age group and variable
age_group_summary <- clean_data %>%
group_by(age_group) %>%
summarize(across(c("pvt_reaction_time_w", "tmt_a_time_w", "tmt_b_time_w"),
list(mean = mean, sd = sd)))
age_group_summary_tmt_diff <- clean_data %>%
group_by(age_group_tmt_diff) %>%
summarize(across(c("tmt_diff_w"),
list(mean = mean, sd = sd)))
View(age_group_summary)
View(clean_data)
# Function to calculate z-scores
calculate_z_scores <- function(x, mean, sd) {
(x - mean) / sd
}
# Function to calculate z-scores for each individual based on age for all variables
calculate_z_scores_individual <- function(x, age, age_group_summary, age_group_summary_tmt_diff) {
# Find the corresponding age group for each individual
age_group <- sapply(age, create_age_groups)
age_group_tmt_diff <- sapply(age, create_age_groups_tmt_diff)
# Join the age group summary data to the individual data based on age group
individual_data <- data.frame(x, age, age_group) %>%
left_join(age_group_summary, by = "age_group") %>%
left_join(age_group_summary_tmt_diff, by = "age_group_tmt_diff")
# Calculate z-scores for all variables
z_scores <- individual_data %>%
mutate(
z_pvt_reaction_time_w = calculate_z_scores(pvt_reaction_time_w, pvt_reaction_time_w_mean, pvt_reaction_time_w_sd),
z_tmt_a_time_w = calculate_z_scores(tmt_a_time_w, tmt_a_time_w_mean, tmt_a_time_w_sd),
z_tmt_b_time_w = calculate_z_scores(tmt_b_time_w, tmt_b_time_w_mean, tmt_b_time_w_sd),
z_tmt_diff_w = calculate_z_scores(tmt_diff_w, tmt_diff_w_mean, tmt_diff_w_sd)
) %>%
select(starts_with("z_"))
# Combine the Z-scores with the original data
x <- cbind(x, z_scores)
return(x)
}
# Calculate z-scores for each individual based on age for all variables
clean_data <- calculate_z_scores_individual(clean_data, clean_data$age, age_group_summary, age_group_summary_tmt_diff)
#------------ 1. load packages------------------
library(tidyverse)
library(carData)
library(car)
library(readr)
library(ggdist)
library(ggExtra)# displaying distributions next to plots
library(ggsignif)# displaying stats in plots
library(ggplot2)
library(ggpubr)
library(coin)# need this for z value of wilcox test
library(effsize)# for cohens d
library(rstatix)# for wilcox test
library(dplyr)
table_power_5 <- read_csv("data/analysis_power/table_power_final_5.csv")
setwd("C:/Users/jankj/OneDrive/Desktop/masters_thesis")
table_power_5 <- read_csv("data/analysis_power/table_power_final_5.csv")
number_of_epochs_5 <- read_csv("data/analysis_power/number_of_epochs_5.csv")
# this would be the amount of people where more than half of the data is good
number_of_epochs%>%
filter(number_epochs > 37.5)# here 70
number_of_epochs%>%
filter(number_epochs > 50)# here 61
number_of_epochs%>%
filter(number_epochs < 51)# these subjects have to be excluded
number_of_epochs_5%>%
filter(number_epochs > 37.5)# here 62
number_of_epochs_5%>%
filter(number_epochs < 37.5)# these subjects have to be excluded
# modify table (f.ex. add tmt b-a)
table_power_5 <- table_power_5%>%
mutate(facit_f_FS = as.numeric(facit_f_FS),
tmt_b_minus_a = tmt_b_time-tmt_a_time)
table_power_5 <- merge(table_power_5, number_of_epochs_5)
test_table <- table_power_5%>%
group_by(participant_id,group,tmt_a_time,facit_f_FS, tmt_b_minus_a,age,years_of_education,number_epochs,cluster_2)%>%
summarise(mean_delta_power = mean(rel_delta),
mean_beta_power = mean(rel_beta),
mean_aperiodic_exponent = mean(aperiodic_exponent))
test_table%>%
group_by(cluster_2)%>%
summarise(mean_age = mean(age),
sd_age = sd(age),
mean_epochs = mean(number_epochs))# sind immerhin fast identisch vom Alter her
t.test(age~cluster_2, data = test_table, alternative = "two.sided")
# Define the channel names you want to select (for delta)
frontal_channels <- c('22','105','11','40','75','39','49','82','48','19','112','25','94','93','83','92','95','96','21','50','10','59','26')
# Filter rows with the specified channel names
table_power_frontal <- table_power_5%>%
filter(table_power_5$channel %in% frontal_channels)
# Define the channel names you want to select (for beta)
central_channels <- c('85','34','65','37','90','66','1','68','3','67','2','70','74','76','81','34','37','42','86','43','87','44','88','45','89','46','77','5','78','6','7','79','8','80','71','35','72','36','73')
# Filter rows with the specified channel names
table_power_central <- table_power_5%>%
filter(table_power_5$channel %in% central_channels)
View(test_table)
setwd("C:/Users/jankj/OneDrive/Desktop/masters_thesis")
#------------ 1. load packages------------------
library(tidyverse)
library(carData)
library(car)
library(readr)
library(ggdist)
library(ggExtra)# displaying distributions next to plots
library(ggsignif)# displaying stats in plots
library(ggplot2)
library(ggpubr)
number_of_epochs_5 <- read_csv("data/analysis_power/number_of_epochs_5.csv")
# this would be the amount of people where more than half of the data is good
number_of_epochs%>%
filter(number_epochs > 37.5)# here 70
number_of_epochs%>%
filter(number_epochs > 50)# here 61
number_of_epochs%>%
filter(number_epochs < 51)# these subjects have to be excluded
number_of_epochs_5%>%
filter(number_epochs > 37.5)# here 62
number_of_epochs_5%>%
filter(number_epochs < 37.5)# these subjects have to be excluded
# modify table (f.ex. add tmt b-a)
table_power_5 <- table_power_5%>%
mutate(facit_f_FS = as.numeric(facit_f_FS),
tmt_b_minus_a = tmt_b_time-tmt_a_time)
table_power_5 <- merge(table_power_5, number_of_epochs_5)
test_table <- table_power_5%>%
group_by(participant_id,group,tmt_a_time,facit_f_FS, tmt_b_minus_a,age,years_of_education,number_epochs,cluster_2)%>%
summarise(mean_delta_power = mean(rel_delta),
mean_beta_power = mean(rel_beta),
mean_aperiodic_exponent = mean(aperiodic_exponent))
test_table%>%
group_by(cluster_2)%>%
summarise(mean_age = mean(age),
sd_age = sd(age),
mean_epochs = mean(number_epochs))# sind immerhin fast identisch vom Alter her
t.test(age~cluster_2, data = test_table, alternative = "two.sided")
#------------ 1. load packages------------------
library(tidyverse)
library(carData)
library(car)
library(readr)
library(ggdist)
library(ggExtra)# displaying distributions next to plots
library(ggsignif)# displaying stats in plots
library(ggplot2)
library(ggpubr)
library(coin)# need this for z value of wilcox test
library(effsize)# for cohens d
library(rstatix)# for wilcox test
library(dplyr)
table_power_5 <- read_csv("data/analysis_power/table_power_final_5.csv")
number_of_epochs_5 <- read_csv("data/analysis_power/number_of_epochs_5.csv")
# this would be the amount of people where more than half of the data is good
number_of_epochs%>%
filter(number_epochs > 37.5)# here 70
number_of_epochs%>%
filter(number_epochs > 50)# here 61
number_of_epochs%>%
filter(number_epochs < 51)# these subjects have to be excluded
number_of_epochs_5%>%
filter(number_epochs > 37.5)# here 62
number_of_epochs_5%>%
filter(number_epochs < 37.5)# these subjects have to be excluded
# modify table (f.ex. add tmt b-a)
table_power_5 <- table_power_5%>%
mutate(facit_f_FS = as.numeric(facit_f_FS),
tmt_b_minus_a = tmt_b_time-tmt_a_time)
table_power_5 <- merge(table_power_5, number_of_epochs_5)
test_table <- table_power_5%>%
group_by(participant_id,group,tmt_a_time,facit_f_FS, tmt_b_minus_a,age,years_of_education,number_epochs,cluster_2)%>%
summarise(mean_delta_power = mean(rel_delta),
mean_beta_power = mean(rel_beta),
mean_aperiodic_exponent = mean(aperiodic_exponent))
View(test_table)
